# Oracle to Snowflake Migration with Azure Data Factory & dbt

> A complete end-to-end data engineering project demonstrating modern data stack implementation

[![dbt](https://img.shields.io/badge/dbt-1.10.15-orange.svg)](https://www.getdbt.com/)
[![Snowflake](https://img.shields.io/badge/Snowflake-Ready-blue.svg)](https://www.snowflake.com/)
[![Azure](https://img.shields.io/badge/Azure-Data%20Factory-0078D4.svg)](https://azure.microsoft.com/en-us/services/data-factory/)

## ğŸ“‹ Project Overview

This project showcases a production-ready data migration and transformation pipeline that migrates data from **Oracle Database** to **Snowflake Data Warehouse** using **Azure Data Factory** for ETL and **dbt (data build tool)** for transformations.

### Business Context
Migration of a retail analytics database with **10 tables** containing sales, customer, product, and cost data from legacy Oracle infrastructure to modern cloud data warehouse architecture.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Oracle Database â”‚ (Source)
â”‚  - 10 Tables    â”‚
â”‚  - DBT_USER     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Azure Data Factory (ADF)         â”‚
â”‚  - Dynamic Pipelines             â”‚
â”‚  - ForEach Loops                 â”‚
â”‚  - Parallel Processing           â”‚
â”‚  - Azure Blob Storage (Staging)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Snowflake Data Warehouse         â”‚
â”‚                                  â”‚
â”‚  ğŸ“Š STAGING Schema               â”‚
â”‚    - Raw Oracle data (10 tables) â”‚
â”‚                                  â”‚
â”‚  ğŸ”„ dbt Transformations          â”‚
â”‚                                  â”‚
â”‚  ğŸ“ˆ INTERMEDIATE_STAGING_DBT     â”‚
â”‚    - 9 Staging Views             â”‚
â”‚                                  â”‚
â”‚  ğŸ¯ INTERMEDIATE_MART            â”‚
â”‚    - 2 Dimension Tables          â”‚
â”‚    - 1 Fact Table                â”‚
â”‚    - 1 Reporting Table           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Key Features

### Data Engineering
- âœ… **Automated ETL Pipeline** - Dynamic ADF pipeline handles all 10 tables
- âœ… **Parallel Processing** - Configurable batch processing (5 tables at a time)
- âœ… **Error Handling** - Robust retry logic and logging
- âœ… **Incremental Loads** - Support for both full and incremental refreshes

### Data Transformation
- âœ… **Modular dbt Models** - 13 transformation models across 3 layers
- âœ… **Data Quality** - Built-in validation and testing
- âœ… **Documentation** - Auto-generated lineage and catalog
- âœ… **Version Control** - All SQL transformations in Git

### Analytics Ready
- âœ… **Dimensional Modeling** - Star schema with facts and dimensions
- âœ… **Customer Analytics** - RFM segmentation and lifetime value
- âœ… **Product Performance** - Category hierarchies and profitability
- âœ… **Sales Reporting** - Time-series analysis and trends

---

## ğŸ“Š Data Models

### Source Tables (Oracle)
| Table | Description | Records |
|-------|-------------|---------|
| CUSTOMERS | Customer demographics | 55K+ |
| PRODUCTS | Product catalog | 72 |
| SALES | Sales transactions | 918K+ |
| COSTS | Product costs | 82K+ |
| CHANNELS | Sales channels | 5 |
| COUNTRIES | Geographic data | 23 |
| TIMES | Date dimension | 1.8K+ |
| PROMOTIONS | Marketing promotions | 503 |
| SUPPLEMENTARY_DEMOGRAPHICS | Additional customer data | - |

### dbt Transformation Layers

#### 1. Staging Layer (9 models)
Clean and standardize raw data:
- `stg_customers` - Customer dimension with age calculation
- `stg_products` - Product catalog with pricing tiers
- `stg_sales` - Sales validation and quality checks
- `stg_costs` - Cost data with margin calculations
- `stg_channels`, `stg_countries`, `stg_times`, `stg_promotions`, `stg_supplementary_demographics`

#### 2. Mart Layer - Dimensions (2 models)
- `dim_customer` - Complete customer profiles with segmentation
- `dim_product` - Product hierarchy and classification

#### 3. Mart Layer - Facts (1 model)
- `fct_sales` - Sales fact with cost and profitability metrics

#### 4. Mart Layer - Reports (1 model)
- `rpt_sales_by_customer` - Customer analytics with RFM analysis

---

## ğŸ› ï¸ Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Source Database** | Oracle Database | Legacy data source |
| **ETL/ELT** | Azure Data Factory | Data orchestration and movement |
| **Staging** | Azure Blob Storage | Temporary data staging |
| **Data Warehouse** | Snowflake | Cloud data warehouse |
| **Transformations** | dbt (data build tool) | SQL-based transformations |
| **Language** | SQL, Python, PowerShell | Development |
| **Version Control** | Git | Code management |

---

## ğŸ“ Project Structure

```
Oracle-SnowFlake-DBt/
â”‚
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ .gitignore                         # Git ignore rules
â”œâ”€â”€ readMe.txt                         # Original project plan
â”‚
â”œâ”€â”€ tables/
â”‚   â”œâ”€â”€ SourceTables.sql              # Oracle DDL scripts
â”‚   â””â”€â”€ Snowflake_Tables.sql          # Snowflake DDL scripts
â”‚
â”œâ”€â”€ ADF_SETUP_GUIDE.md                # Azure Data Factory setup
â”œâ”€â”€ SNOWFLAKE_SETUP_GUIDE.md          # Snowflake configuration
â”‚
â”œâ”€â”€ oracle_snowflake_dbt/             # dbt Project
â”‚   â”œâ”€â”€ dbt_project.yml               # dbt configuration
â”‚   â”œâ”€â”€ profiles.yml                  # Snowflake connection (gitignored)
â”‚   â”œâ”€â”€ .env.template                 # Environment variables template
â”‚   â”œâ”€â”€ run_dbt.ps1                   # PowerShell helper script
â”‚   â”‚
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ staging/
â”‚       â”‚   â”œâ”€â”€ sources.yml           # Source definitions
â”‚       â”‚   â”œâ”€â”€ stg_customers.sql
â”‚       â”‚   â”œâ”€â”€ stg_products.sql
â”‚       â”‚   â”œâ”€â”€ stg_sales.sql
â”‚       â”‚   â””â”€â”€ ... (6 more)
â”‚       â”‚
â”‚       â””â”€â”€ marts/
â”‚           â”œâ”€â”€ core/
â”‚           â”‚   â”œâ”€â”€ dim_customer.sql
â”‚           â”‚   â”œâ”€â”€ dim_product.sql
â”‚           â”‚   â””â”€â”€ fct_sales.sql
â”‚           â”‚
â”‚           â””â”€â”€ reporting/
â”‚               â””â”€â”€ rpt_sales_by_customer.sql
â”‚
â””â”€â”€ Documentation/
    â”œâ”€â”€ DBT_SETUP_GUIDE.md
    â”œâ”€â”€ DBT_MODELS_PLAN.md
    â””â”€â”€ COMPLETE_DBT_PROJECT_SUMMARY.md
```

---

## ğŸš€ Getting Started

### Prerequisites
- Oracle Database access
- Azure subscription with Data Factory
- Snowflake account
- Python 3.8+ with dbt-snowflake
- Git

### Installation

1. **Clone the repository**
```bash
git clone <your-repo-url>
cd Oracle-SnowFlake-DBt
```

2. **Set up Python virtual environment**
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
pip install dbt-snowflake
```

3. **Configure credentials**
```bash
cd oracle_snowflake_dbt
cp .env.template .env
# Edit .env with your Snowflake credentials
```

4. **Test dbt connection**
```powershell
.\run_dbt.ps1 debug
```

5. **Run transformations**
```powershell
.\run_dbt.ps1 run
```

---

## ğŸ“ˆ Sample Analytics Queries

### Top 10 Customers by Revenue
```sql
SELECT
    full_name,
    total_revenue,
    total_transactions,
    customer_segment,
    customer_lifetime_value
FROM INTERMEDIATE_MART.rpt_sales_by_customer
ORDER BY total_revenue DESC
LIMIT 10;
```

### Product Profitability Analysis
```sql
SELECT
    p.category,
    p.product_name,
    SUM(s.amount_sold) AS revenue,
    SUM(s.gross_profit) AS profit,
    AVG(s.profit_margin_percentage) AS avg_margin_pct
FROM INTERMEDIATE_MART.fct_sales s
JOIN INTERMEDIATE_MART.dim_product p ON s.product_id = p.product_id
GROUP BY p.category, p.product_name
ORDER BY profit DESC;
```

### Customer Segmentation Distribution
```sql
SELECT
    customer_segment,
    COUNT(*) AS customer_count,
    SUM(total_revenue) AS segment_revenue,
    AVG(customer_lifetime_value) AS avg_clv
FROM INTERMEDIATE_MART.rpt_sales_by_customer
GROUP BY customer_segment
ORDER BY segment_revenue DESC;
```

---

## ğŸ§ª Testing & Quality

### dbt Tests
```powershell
# Run all tests
.\run_dbt.ps1 test

# Test specific model
.\run_dbt.ps1 test --select dim_customer
```

### Data Quality Checks
- âœ… Unique primary keys
- âœ… Not null constraints
- âœ… Referential integrity
- âœ… Valid date ranges
- âœ… Positive amounts

---

## ğŸ“š Documentation

### Generate dbt Docs
```powershell
.\run_dbt.ps1 docs generate
.\run_dbt.ps1 docs serve
```

This creates an interactive website with:
- ğŸ“Š Data lineage diagrams
- ğŸ“ Model descriptions
- ğŸ”— Column-level documentation
- ğŸŒ³ Dependency graphs

---

## ğŸ“ Skills Demonstrated

### Data Engineering
- Cloud data warehouse architecture (Snowflake)
- ETL pipeline development (Azure Data Factory)
- SQL optimization and performance tuning
- Data modeling (dimensional modeling)

### Development & DevOps
- Version control (Git)
- Infrastructure as Code
- Automation and scripting (PowerShell, Python)
- CI/CD practices

### Analytics Engineering
- dbt transformations
- Data quality testing
- Documentation generation
- Analytics-ready data modeling

---

## ğŸ“Š Performance Metrics

- **Pipeline Execution Time**: ~15-30 minutes (for full refresh)
- **Data Volume**: 1M+ records processed
- **Tables Migrated**: 10 source tables
- **Models Created**: 13 dbt models
- **Parallel Processing**: 5 tables simultaneously

---

## ğŸ” Security & Best Practices

- âœ… Credentials stored in `.env` files (gitignored)
- âœ… Azure SAS tokens for secure blob access
- âœ… Snowflake role-based access control
- âœ… Encrypted data in transit
- âœ… Audit trails and logging

---

## ğŸ›£ï¸ Roadmap & Future Enhancements

- [ ] Implement incremental models for large fact tables
- [ ] Add data quality monitoring dashboard
- [ ] Schedule automated pipeline runs
- [ ] Implement slowly changing dimensions (SCD Type 2)
- [ ] Create Power BI/Tableau dashboards
- [ ] Add real-time CDC (Change Data Capture)

---

## ğŸ“ License

This project is available for educational and portfolio purposes.

---

## ğŸ¤ Connect

**Author**: Srinivas Perumandla
**LinkedIn**: https://www.linkedin.com/in/srinivs-p
**GitHub**:  https://github.com/Srinivs-p
**Email**: *********@****.com 

---

## ğŸ™ Acknowledgments

- Oracle sample database (SH schema)
- dbt community for best practices
- Snowflake documentation
- Azure Data Factory tutorials

---

## ğŸ“¸ Screenshots

### dbt Lineage Graph
![dbt Lineage](docs/images/dbt-lineage.png)

### Snowflake Data Model
![Data Model](docs/images/data-model.png)

### ADF Pipeline
![ADF Pipeline](docs/images/adf-pipeline.png)

---

**â­ If you found this project helpful, please consider giving it a star!**
